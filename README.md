# Transparent-Objects-Pose-Estimation-via-RGB-D-Enhancement-and-Depth-Directed-Feature-Fusion

# Abstract
Estimating the 6D pose of transparent objects remains a challenging task due to weak visual cues and incomplete depth information caused by refractions and additional reflections from the backsides of transparent objects. These challenges often lead to inaccurate perception and localization. Existing approaches struggle to jointly enhance RGB and depth features or fully exploit depth information. In this paper, we propose a depth-directed method that integrates stable diffusion and Mamba-based RGB-D augmentation to address these limitations. Specifically, we use a stable diffusion model to enhance the visibility of transparent objects in RGB images by recovering texture details and reducing background interference. Then, a Mamba-based network completes the sparse and noisy raw depth maps using guidance from the refined RGB features. To effectively fuse the two modalities, we introduce a multi-scale RGB-D fusion strategy, where the completed depth not only provides geometric information but also guides RGB feature extraction. This joint representation leads to more accurate and robust 6D pose estimation. Experimental results on challenging datasets demonstrate that our method significantly enhances object visibility and improves pose estimation accuracy in complex real-world scenes.
